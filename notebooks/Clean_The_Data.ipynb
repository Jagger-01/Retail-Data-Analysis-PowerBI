{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4149fa-9fe9-430e-ac5c-cb239528bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'..\\data\\raw\\retail_data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c039111-d3c3-4bf0-92e3-88fbb36332c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before cleaning: 302010\n",
      "Number of missing values before cleaning:\n",
      "Transaction_ID      333\n",
      "Customer_ID         308\n",
      "Name                382\n",
      "Email               347\n",
      "Phone               362\n",
      "Age                 173\n",
      "Gender              317\n",
      "Income              290\n",
      "Customer_Segment    215\n",
      "Date                359\n",
      "Time                350\n",
      "Product_Category    283\n",
      "Product_Brand       281\n",
      "Product_Type          0\n",
      "Feedback            184\n",
      "Shipping_Method     337\n",
      "Payment_Method      297\n",
      "Order_Status        235\n",
      "Ratings             184\n",
      "products              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows before cleaning\n",
    "print(\"Number of rows before cleaning:\", len(df))\n",
    "\n",
    "# Print the number of missing values before cleaning for specified columns\n",
    "columns_to_check = ['Transaction_ID', 'Customer_ID', 'Name', 'Email', 'Phone', 'Age', 'Gender', 'Income', 'Customer_Segment', 'Date', 'Time', 'Product_Category', 'Product_Brand', 'Product_Type', 'Feedback', 'Shipping_Method', 'Payment_Method', 'Order_Status', 'Ratings', 'products']\n",
    "print(\"Number of missing values before cleaning:\")\n",
    "print(df[columns_to_check].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70452ada-d6a6-4f03-bc9c-61c119984fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning: 296994\n",
      "Number of missing values after cleaning:\n",
      "Transaction_ID      0\n",
      "Customer_ID         0\n",
      "Name                0\n",
      "Email               0\n",
      "Phone               0\n",
      "Age                 0\n",
      "Gender              0\n",
      "Income              0\n",
      "Customer_Segment    0\n",
      "Date                0\n",
      "Time                0\n",
      "Product_Category    0\n",
      "Product_Brand       0\n",
      "Product_Type        0\n",
      "Feedback            0\n",
      "Shipping_Method     0\n",
      "Payment_Method      0\n",
      "Order_Status        0\n",
      "Ratings             0\n",
      "products            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Drop rows where any of the specified columns have missing values\n",
    "df_cleaned = df.dropna(subset=columns_to_check)\n",
    "\n",
    "# Print the number of rows after cleaning\n",
    "print(\"Number of rows after cleaning:\", len(df_cleaned))\n",
    "\n",
    "# Print the number of missing values after cleaning for specified columns\n",
    "print(\"Number of missing values after cleaning:\")\n",
    "print(df_cleaned[columns_to_check].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eded9af-1ef2-42bd-a1e2-fd79671a9df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 duplicate sets based on Transaction_ID and Customer_ID:\n",
      "\n",
      "Duplicate group for Transaction_ID = 1005039.0 and Customer_ID = 84239.0:\n",
      "\n",
      "        Transaction_ID  Customer_ID       Name               Email  \\\n",
      "165944       1005039.0      84239.0  John Tate  Andrea27@gmail.com   \n",
      "301783       1005039.0      84239.0  John Tate  Andrea27@gmail.com   \n",
      "\n",
      "               Phone              Address  City   State  Zipcode  Country  \\\n",
      "165944  9.064051e+09  7563 Pittman Tunnel  Bonn  Berlin  35327.0  Germany   \n",
      "301783  9.064051e+09  7563 Pittman Tunnel  Bonn  Berlin  35327.0  Germany   \n",
      "\n",
      "        ...  Total_Amount Product_Category Product_Brand Product_Type  \\\n",
      "165944  ...   1114.320116          Grocery     Coca-Cola        Water   \n",
      "301783  ...   1114.320116          Grocery     Coca-Cola        Water   \n",
      "\n",
      "       Feedback  Shipping_Method Payment_Method Order_Status  Ratings  \\\n",
      "165944      Bad         Same-Day     Debit Card      Pending      1.0   \n",
      "301783      Bad         Same-Day           Cash      Pending      1.0   \n",
      "\n",
      "               products  \n",
      "165944   Flavored water  \n",
      "301783  Sparkling water  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Duplicate group for Transaction_ID = 1010919.0 and Customer_ID = 12847.0:\n",
      "\n",
      "        Transaction_ID  Customer_ID        Name              Email  \\\n",
      "273886       1010919.0      12847.0  Tyler Ward  Louis68@gmail.com   \n",
      "300651       1010919.0      12847.0  Tyler Ward  Louis68@gmail.com   \n",
      "\n",
      "               Phone            Address       City    State  Zipcode Country  \\\n",
      "273886  4.553740e+09  945 Justin Street  Vancouver  Ontario  79443.0  Canada   \n",
      "300651  4.553740e+09  945 Justin Street  Vancouver  Ontario  79443.0  Canada   \n",
      "\n",
      "        ...  Total_Amount Product_Category Product_Brand Product_Type  \\\n",
      "273886  ...   1361.597034      Electronics       Samsung   Television   \n",
      "300651  ...   1361.597034      Electronics       Samsung   Television   \n",
      "\n",
      "       Feedback  Shipping_Method Payment_Method Order_Status  Ratings  \\\n",
      "273886     Good         Same-Day    Credit Card    Delivered      3.0   \n",
      "300651     Good         Same-Day           Cash    Delivered      3.0   \n",
      "\n",
      "        products  \n",
      "273886    LED TV  \n",
      "300651    LED TV  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Duplicate group for Transaction_ID = 1019366.0 and Customer_ID = 21198.0:\n",
      "\n",
      "        Transaction_ID  Customer_ID                Name                Email  \\\n",
      "97360        1019366.0      21198.0  Timothy Montgomery  Cynthia36@gmail.com   \n",
      "300395       1019366.0      21198.0  Timothy Montgomery  Cynthia36@gmail.com   \n",
      "\n",
      "               Phone               Address      City    State  Zipcode  \\\n",
      "97360   8.622075e+09  385 Gabrielle Estate  Winnipeg  Ontario  69618.0   \n",
      "300395  8.622075e+09  385 Gabrielle Estate  Winnipeg  Ontario  69618.0   \n",
      "\n",
      "       Country  ...  Total_Amount Product_Category Product_Brand Product_Type  \\\n",
      "97360   Canada  ...   1417.142399          Grocery        Nestle       Snacks   \n",
      "300395  Canada  ...   1417.142399          Grocery        Nestle       Snacks   \n",
      "\n",
      "         Feedback  Shipping_Method Payment_Method Order_Status  Ratings  \\\n",
      "97360     Average          Express         PayPal      Shipped      2.0   \n",
      "300395  Excellent          Express    Credit Card      Shipped      4.0   \n",
      "\n",
      "             products  \n",
      "97360        Pretzels  \n",
      "300395  Cheese snacks  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Removed 4628 duplicates. New DataFrame length: 294680\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check for duplicates based on both Transaction_ID and Customer_ID\n",
    "duplicates = df_cleaned[df_cleaned.duplicated(subset=['Transaction_ID', 'Customer_ID'], keep=False)]\n",
    "\n",
    "# Print the first 3 sets of duplicates side by side\n",
    "if not duplicates.empty:\n",
    "    print(\"First 3 duplicate sets based on Transaction_ID and Customer_ID:\\n\")\n",
    "    grouped_duplicates = duplicates.groupby(['Transaction_ID', 'Customer_ID'])\n",
    "    \n",
    "    for name, group in list(grouped_duplicates)[:3]:\n",
    "        print(f\"Duplicate group for Transaction_ID = {name[0]} and Customer_ID = {name[1]}:\\n\")\n",
    "        print(group)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Remove duplicates, keeping only the first occurrence\n",
    "    df_cleaned = df_cleaned.drop_duplicates(subset=['Transaction_ID', 'Customer_ID'], keep='first')\n",
    "\n",
    "    # Print confirmation\n",
    "    print(f\"Removed {len(duplicates)} duplicates. New DataFrame length: {len(df_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf385416-70d8-440d-bf1f-52a5def93b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before handling 'Amount', 'Total_Purchases', and 'Total_Amount':\n",
      "Amount             349\n",
      "Total_Purchases    355\n",
      "Total_Amount       342\n",
      "dtype: int64\n",
      "Filling in missing 'Amount' values...\n",
      "Missing values after filling 'Amount':\n",
      "1\n",
      "Filling in missing 'Total_Purchases' values...\n",
      "Missing values after filling 'Total_Purchases':\n",
      "0\n",
      "Filling in missing 'Total_Amount' values...\n",
      "Missing values after filling 'Total_Amount':\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle missing 'Amount', 'Total_Purchases', and 'Total_Amount' values\n",
    "columns_to_check_amounts = ['Amount', 'Total_Purchases', 'Total_Amount']\n",
    "print(\"Number of missing values before handling 'Amount', 'Total_Purchases', and 'Total_Amount':\")\n",
    "print(df_cleaned[columns_to_check_amounts].isnull().sum())\n",
    "\n",
    "# Fill in missing 'Amount' values\n",
    "print(\"Filling in missing 'Amount' values...\")\n",
    "df_cleaned['Amount'] = df_cleaned.apply(lambda row: row['Total_Amount'] / row['Total_Purchases'] if pd.isnull(row['Amount']) and pd.notnull(row['Total_Amount']) and pd.notnull(row['Total_Purchases']) else row['Amount'], axis=1)\n",
    "print(\"Missing values after filling 'Amount':\")\n",
    "print(df_cleaned['Amount'].isnull().sum())\n",
    "\n",
    "# Fill in missing 'Total_Purchases' values\n",
    "print(\"Filling in missing 'Total_Purchases' values...\")\n",
    "df_cleaned['Total_Purchases'] = df_cleaned.apply(lambda row: np.round(row['Total_Amount'] / row['Amount']) if pd.isnull(row['Total_Purchases']) and pd.notnull(row['Total_Amount']) and pd.notnull(row['Amount']) else row['Total_Purchases'], axis=1)\n",
    "print(\"Missing values after filling 'Total_Purchases':\")\n",
    "print(df_cleaned['Total_Purchases'].isnull().sum())\n",
    "\n",
    "# Fill in missing 'Total_Amount' values\n",
    "print(\"Filling in missing 'Total_Amount' values...\")\n",
    "df_cleaned['Total_Amount'] = df_cleaned.apply(lambda row: row['Total_Purchases'] * row['Amount'] if pd.isnull(row['Total_Amount']) and pd.notnull(row['Total_Purchases']) and pd.notnull(row['Amount']) else row['Total_Amount'], axis=1)\n",
    "print(\"Missing values after filling 'Total_Amount':\")\n",
    "print(df_cleaned['Total_Amount'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd2ee50-5c29-4553-964e-96b63f6d39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop rows with any missing values in 'Amount', 'Total_Purchases', or 'Total_Amount'\n",
    "df_cleaned = df_cleaned.dropna(subset=columns_to_check_amounts)\n",
    "\n",
    "# Function to parse dates with multiple formats\n",
    "def parse_dates(date_str):\n",
    "    try:\n",
    "        # Try parsing with the first format MM/DD/YYYY\n",
    "        return pd.to_datetime(date_str, format='%m/%d/%Y')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Try parsing with the second format MM-DD-YY\n",
    "            return pd.to_datetime(date_str, format='%m-%d-%y')\n",
    "        except ValueError:\n",
    "            return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe33bf3c-bbe4-48a5-b807-04df7f686403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the 'Date' column before conversion:\n",
      "0     9/18/2023\n",
      "1    12/31/2023\n",
      "2     4/26/2023\n",
      "3      05-08-23\n",
      "4      01-10-24\n",
      "5     9/21/2023\n",
      "6     6/26/2023\n",
      "7     3/24/2023\n",
      "8      01-06-24\n",
      "9      10-04-23\n",
      "Name: Date, dtype: object\n",
      "First 10 rows of the 'Date' column after conversion:\n",
      "0   2023-09-18\n",
      "1   2023-12-31\n",
      "2   2023-04-26\n",
      "3   2023-05-08\n",
      "4   2024-01-10\n",
      "5   2023-09-21\n",
      "6   2023-06-26\n",
      "7   2023-03-24\n",
      "8   2024-01-06\n",
      "9   2023-10-04\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "Total number of rows after deleting NaT dates: 294679\n",
      "First 10 rows of the new 'Year', 'Month', and 'Day_of_Week' columns:\n",
      "   Year      Month Day_of_Week\n",
      "0  2023  September      Monday\n",
      "1  2023   December      Sunday\n",
      "2  2023      April   Wednesday\n",
      "3  2023        May      Monday\n",
      "4  2024    January   Wednesday\n",
      "5  2023  September    Thursday\n",
      "6  2023       June      Monday\n",
      "7  2023      March      Friday\n",
      "8  2024    January    Saturday\n",
      "9  2023    October   Wednesday\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Remove 'Year' and 'Month' columns\n",
    "df_cleaned = df_cleaned.drop(columns=['Year', 'Month'])\n",
    "\n",
    "# Print the first few rows of the Date column before conversion\n",
    "print(\"First 10 rows of the 'Date' column before conversion:\")\n",
    "print(df_cleaned['Date'].head(10))\n",
    "\n",
    "# Apply the custom date parsing function\n",
    "df_cleaned['Date'] = df_cleaned['Date'].apply(parse_dates)\n",
    "\n",
    "# Verify the 'Date' column after conversion\n",
    "print(\"First 10 rows of the 'Date' column after conversion:\")\n",
    "print(df_cleaned['Date'].head(10))\n",
    "\n",
    "# Delete rows where 'Date' is NaT\n",
    "df_cleaned = df_cleaned.dropna(subset=['Date'])\n",
    "\n",
    "# Print the total number of rows after deletion\n",
    "print(\"Total number of rows after deleting NaT dates:\", len(df_cleaned))\n",
    "\n",
    "# Step 6: Create 'Year', 'Month', and 'Day_of_Week' columns\n",
    "df_cleaned['Year'] = df_cleaned['Date'].dt.year\n",
    "df_cleaned['Month'] = df_cleaned['Date'].dt.strftime('%B')  # Full month name (e.g., 'September')\n",
    "df_cleaned['Day_of_Week'] = df_cleaned['Date'].dt.strftime('%A')  # Full day name (e.g., 'Monday')\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"First 10 rows of the new 'Year', 'Month', and 'Day_of_Week' columns:\")\n",
    "print(df_cleaned[['Year', 'Month', 'Day_of_Week']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af40ef26-0075-4e94-93f6-aea208903861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Drop rows where either 'Zipcode' or 'Address' is missing\n",
    "df_cleaned = df_cleaned.dropna(subset=['Zipcode', 'Address'])\n",
    "\n",
    "# Step 8: Reset index to avoid any potential issues\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Define a function to fill missing values based on other columns\n",
    "def fill_missing_values(group):\n",
    "    for col in ['City', 'State', 'Country']:\n",
    "        if pd.isnull(group[col].iloc[0]):\n",
    "            non_null_value = group[col].dropna().unique()\n",
    "            if len(non_null_value) == 1:\n",
    "                group[col].fillna(non_null_value[0], inplace=True)\n",
    "    return group\n",
    "\n",
    "# Step 9: Group by 'City', 'State', and 'Country' and apply the fill_missing_values function\n",
    "df_cleaned = df_cleaned.groupby(['City', 'State', 'Country'], as_index=False).apply(fill_missing_values)\n",
    "\n",
    "# Step 10: Drop any remaining rows with missing 'City', 'State', or 'Country' values after filling\n",
    "df_cleaned = df_cleaned.dropna(subset=['City', 'State', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05af31f3-2a0e-4046-b48f-95db97d277b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final check for any remaining missing values in all columns:\n",
      "Transaction_ID      0\n",
      "Customer_ID         0\n",
      "Name                0\n",
      "Email               0\n",
      "Phone               0\n",
      "Address             0\n",
      "City                0\n",
      "State               0\n",
      "Zipcode             0\n",
      "Country             0\n",
      "Age                 0\n",
      "Gender              0\n",
      "Income              0\n",
      "Customer_Segment    0\n",
      "Date                0\n",
      "Time                0\n",
      "Total_Purchases     0\n",
      "Amount              0\n",
      "Total_Amount        0\n",
      "Product_Category    0\n",
      "Product_Brand       0\n",
      "Product_Type        0\n",
      "Feedback            0\n",
      "Shipping_Method     0\n",
      "Payment_Method      0\n",
      "Order_Status        0\n",
      "Ratings             0\n",
      "products            0\n",
      "Year                0\n",
      "Month               0\n",
      "Day_of_Week         0\n",
      "dtype: int64\n",
      "Total number of rows after cleaning and processing: 293267\n",
      "Data successfully saved as CSV to: ..\\data\\cleaned\\retail_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Final check for any remaining missing values in the entire DataFrame\n",
    "print(\"Final check for any remaining missing values in all columns:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Print the total number of rows after all cleaning steps\n",
    "print(\"Total number of rows after cleaning and processing:\", len(df_cleaned))\n",
    "\n",
    "#Save\n",
    "csv_output_path = r'..\\data\\cleaned\\retail_data_cleaned.csv'\n",
    "df_cleaned.to_csv(csv_output_path, index=False)\n",
    "print(f\"Data successfully saved as CSV to: {csv_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
